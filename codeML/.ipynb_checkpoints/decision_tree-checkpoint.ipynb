{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e8fa6f-8d1d-4a9b-84f6-f2b11d24bf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"figure2.csv\", 'r') as file:\n",
    "    data = file.read().split('\\n')[1:]\n",
    "\n",
    "rows = [a.split(',') for a in data if a[0] == 'r']\n",
    "heads = [data[i+1].split(',')[0] for i, a in enumerate(data) if a[0] == 'r'] \n",
    "\n",
    "for i in range(len(rows)):\n",
    "    rows[i] = [b for b in rows[i] if b]\n",
    "    rows[i].extend(rows[i].pop(-1).split(' '))\n",
    "    rows[i] = [b for b in rows[i] if b]\n",
    "    rows[i][0] = heads[i]\n",
    "t_data = list(zip(*rows))\n",
    "\n",
    "df = pd.DataFrame(t_data[1:], columns=t_data[0])\n",
    "df[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7918ebf4-29d1-439e-b041-8215af201017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        blue\n",
       "1        blue\n",
       "2        blue\n",
       "3        blue\n",
       "4        blue\n",
       "        ...  \n",
       "2981    brown\n",
       "2982    brown\n",
       "2983    brown\n",
       "2984    brown\n",
       "2985    brown\n",
       "Name: eye_color, Length: 2986, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blue = [0]*2234\n",
    "green = [1]*428\n",
    "brown = [2]*324\n",
    "data_dict = {}\n",
    "data_dict['eye_color'] = blue + green + brown\n",
    "col_count = [2234, 428, 324]\n",
    "\n",
    "for pheno in df.columns:\n",
    "    data_dict[pheno] = []\n",
    "    for i, stat in enumerate(list(df[pheno][1:4])):\n",
    "        amount = round(col_count[i]*(float(stat)/100))\n",
    "        l = [1]*amount + [0]*(col_count[i]-amount)\n",
    "        random.shuffle(l)\n",
    "        data_dict[pheno].extend(l)\n",
    "final_df = pd.DataFrame(data_dict)  \n",
    "col_mv = final_df.pop(\"eye_color\")\n",
    "final_df.insert(9, \"eye_color\", col_mv)\n",
    "eye_color = final_df['eye_color'].copy()\n",
    "eye_color.loc[eye_color == 0] = \"blue\"\n",
    "eye_color.loc[eye_color == 1] = \"green\"\n",
    "eye_color.loc[eye_color == 2] = \"brown\"\n",
    "eye_color\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7788263-8da2-487a-9c5e-6175cf9de36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, \n",
    "                 feature_index=None,\n",
    "                 threshold=None,\n",
    "                 left_node=None,\n",
    "                 right_node=None,\n",
    "                 info_gain=None,\n",
    "                 id=None,\n",
    "                 depth=None,\n",
    "                 value=None,\n",
    "                 types=None):\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.right_node = right_node\n",
    "        self.left_node = left_node\n",
    "        self.info_gain = info_gain\n",
    "        self.id = id\n",
    "        self.depth = depth\n",
    "        self.types = types\n",
    "        # for leaf nnode\n",
    "        self.value = value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "14cc9624-eba1-4796-a019-4c96e974d534",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, min_sample_split=30, max_depth=12):\n",
    "        self.root = None\n",
    "\n",
    "        #stopping conditions\n",
    "        self.min_sample_split = min_sample_split\n",
    "        self.max_depth = max_depth\n",
    "    def build_tree(self, dataset, curr_depth=0, id=0):\n",
    "\n",
    "        X, Y = dataset[:,:-1], dataset[:,-1]\n",
    "        num_samples, num_features = np.shape(X)\n",
    "        #print(num_samples, num_features)\n",
    "\n",
    "        if num_samples >= self.min_sample_split and curr_depth <= self.max_depth:\n",
    "            best_split = self.get_best_split(dataset, num_samples, num_features)\n",
    "            #print(best_split[\"curr_gain\"])\n",
    "            #print(curr_depth)\n",
    "            if best_split[\"curr_gain\"] > 0:\n",
    "            # left set\n",
    "                left_subtree = self.build_tree(best_split[\"dataset_left\"], curr_depth+1, id*2 + 1)\n",
    "                #print(left_subtree)\n",
    "                # right set\n",
    "                right_subtree = self.build_tree(best_split[\"dataset_right\"], curr_depth+1, id*2 + 2)\n",
    "                \n",
    "\n",
    "                return Node(best_split[\"feature_index\"], best_split[\"threshold\"], left_subtree, right_subtree, best_split[\"curr_gain\"]\n",
    "                            ,depth=curr_depth, id=id, types=Y)\n",
    "\n",
    "        leaf_value = self.get_leaf_value(Y)\n",
    "        #print(leaf_value)\n",
    "        return Node(value=leaf_value, depth=curr_depth, id=id, types=Y)\n",
    "\n",
    "    def get_best_split(self, dataset, num_samples, num_features):\n",
    "        best_split = {\"curr_gain\": 0}\n",
    "        max_infogain = -1000000000\n",
    "\n",
    "        for feature_index in range(num_features):\n",
    "            feature_values = dataset[:,feature_index]\n",
    "            possible_thresholds = np.unique(feature_values)\n",
    "            for threshold in possible_thresholds:\n",
    "                dataset_left, dataset_right = self.split(dataset, feature_index, threshold) \n",
    "                if len(dataset_left) > 0 and len(dataset_right) > 0:\n",
    "                    y, y_left, y_right = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n",
    "                    info_gain = self.information_gain(y, y_left, y_right, \"gini\")\n",
    "                    #print(info_gain)\n",
    "                    if info_gain > max_infogain:\n",
    "                        #print('yay')\n",
    "                        best_split[\"dataset_left\"] = dataset_left\n",
    "                        best_split[\"dataset_right\"] = dataset_right\n",
    "                        best_split[\"feature_index\"] = feature_index\n",
    "                        best_split[\"threshold\"] = threshold\n",
    "                        best_split[\"curr_gain\"] = info_gain\n",
    "                        max_infogain = info_gain\n",
    "        #rint(max_infogain)\n",
    "        return best_split\n",
    "\n",
    "    def split(self, dataset, feature_index, threshold):\n",
    "        dataset_left = np.array([sample for sample in dataset if sample[feature_index] <= threshold] )\n",
    "        dataset_right = np.array([sample for sample in dataset if sample[feature_index] > threshold])\n",
    "        return dataset_left, dataset_right        \n",
    "    \n",
    "    def information_gain(self, y, y_left, y_right, type):\n",
    "        # weights might use later \n",
    "        weight_l = len(y_left)/len(y)\n",
    "        weight_r = len(y_right)/len(y)\n",
    "        if type == \"gini\":\n",
    "            info_gain = self.gini_index(y) - (weight_l*self.gini_index(y_left) + weight_r*self.gini_index(y_right))\n",
    "            #print(info_gain)\n",
    "        # entropy maybe\n",
    "        return info_gain\n",
    "\n",
    "    def gini_index(self, y):\n",
    "        class_labels = np.unique(y)\n",
    "        gini = 0\n",
    "        for cls in class_labels:\n",
    "            p_cls = len(y[y==cls])/len(y)\n",
    "            gini += p_cls**2\n",
    "        #print(1- gini)\n",
    "        return 1 - gini\n",
    "\n",
    "    def get_leaf_value(self, y):\n",
    "        values = list(y)\n",
    "        return max(values, key=values.count)\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        dataset = np.concatenate((x, y), axis=1)\n",
    "        #print(dataset)\n",
    "        self.root = self.build_tree(dataset)\n",
    "\n",
    "    def print_tree(self, tree=None, depth=0, leaf_l=[], inner_l=[]):\n",
    "        if not tree:\n",
    "            tree = self.root\n",
    "            #print(self.root.feature_index)\n",
    "        if tree.value is not None:\n",
    "            leaf_l.append(tree)\n",
    "            #print(\"leaf: id=\"+str(tree.id) + \" depth=\" + str(tree.depth)+ \" value=\"+ str(tree.value))\n",
    "            \n",
    "        else:\n",
    "            inner_l.append(tree)\n",
    "            #print(\" id=\" + str(tree.id) + \" depth=\" + str(tree.depth) + \" X_\"+str(tree.feature_index), \" thresh: \"+str(tree.threshold), \" info \", tree.info_gain)\n",
    "            #print(f\"left:\")\n",
    "            leaf_l, inner_l = self.print_tree(tree.left_node, depth + 1, leaf_l, inner_l)\n",
    "            #print(f\"right:\")\n",
    "            leaf_l, inner_l = self.print_tree(tree.right_node, depth + 1, leaf_l, inner_l)\n",
    "        return leaf_l, inner_l\n",
    " \n",
    "    # predict 1\n",
    "    def make_prediction(self, x, tree):\n",
    "        if tree.value != None:\n",
    "            #print(tree.value)\n",
    "            return tree.value\n",
    "        feature_val = x[tree.feature_index]\n",
    "        if feature_val <= tree.threshold:\n",
    "            return self.make_prediction(x, tree.left_node)\n",
    "        else:\n",
    "            return self.make_prediction(x, tree.right_node)\n",
    "            \n",
    "    def predict(self, set, root=None):\n",
    "        if not root:\n",
    "            root = self.root\n",
    "        predictions = [self.make_prediction(x, root) for x in set]\n",
    "        return predictions\n",
    "        # predict 1\n",
    "\n",
    "    found = False\n",
    "    def pruning(self, prunedList, tree=None):\n",
    "        \n",
    "        if self.found:\n",
    "            return tree\n",
    "        if tree == None:\n",
    "            tree = self.root\n",
    "            print(tree.left_node.id, tree.right_node.right_node.id)\n",
    "        print(tree.id,end = \" \")\n",
    "        if tree.value:\n",
    "            print(tree.id, prunedList,end = \" \")\n",
    "            return tree\n",
    "        \n",
    "        if int(tree.id) == prunedList[0]:\n",
    "            print('hello', end=\" \")\n",
    "            tree.value = self.get_leaf_value(tree.types)\n",
    "            self.found = True\n",
    "            return tree\n",
    "        self.pruning(prunedList, tree.left_node)\n",
    "        if self.found:\n",
    "            return tree\n",
    "\n",
    "        self.pruning(prunedList, tree.right_node)\n",
    "        if self.found:\n",
    "            return tree\n",
    "\n",
    "        return tree\n",
    "\n",
    "    \n",
    "  \n",
    "        \n",
    "        \n",
    "\n",
    "X = final_df.iloc[:, :-1].values\n",
    "Y = final_df.iloc[:, -1].values.reshape(-1,1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=41)\n",
    "\n",
    "classifier = DecisionTree()\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "#classifier.print_tree()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "a5c96a87-7a96-498f-b2c2-1074520293a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7625418060200669\n",
      "0.970917225950783\n",
      "0.012048192771084338\n",
      "0.3088235294117647\n"
     ]
    }
   ],
   "source": [
    "#classifier.print_tree()\n",
    "\n",
    "Y_pred = list(classifier.predict(X_test))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_test, Y_pred))\n",
    "\n",
    "#print(len([1 for i, a in enumerate(Y_test) if a == 2 and Y_pred[i] == 2])/len([a for a in Y_test if a == 2]))\n",
    "\n",
    "for type in [0, 1, 2]:\n",
    "    print(len([1 for i, a in enumerate(Y_test) if a == type and Y_pred[i] == type])/len([a for a in Y_test if a == type]) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "83b3a7f0-25c9-47e6-adee-e414aab0be57",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf, inner = classifier.print_tree()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "a9ceb369-1ec0-46f6-94af-4688aa1f2052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 135, 136, 68, 139, 140, 70, 8, 4, 23, 24, 12, 895, 896, 897, 898, 224, 112, 227, 457, 458, 114, 927, 928, 464, 931, 932, 466, 935, 936, 937, 938, 939, 940, 470, 943, 944, 472, 947, 948, 474, 951, 952, 476, 238, 959, 960, 480, 963, 964, 482, 483, 484, 971, 972, 486, 975, 976, 488, 244, 983, 984, 985, 986, 246, 991, 992, 496, 995, 996, 498, 999, 1000, 500, 250, 125, 126]\n",
      "[0, 1, 3, 7, 16, 33, 67, 34, 69, 2, 5, 11, 6, 13, 27, 55, 111, 223, 447, 448, 56, 113, 228, 28, 57, 115, 231, 463, 232, 465, 116, 233, 467, 468, 234, 469, 58, 117, 235, 471, 236, 473, 118, 237, 475, 14, 29, 59, 119, 239, 479, 240, 481, 120, 241, 242, 485, 60, 121, 243, 487, 122, 245, 491, 492, 30, 61, 123, 247, 495, 248, 497, 124, 249, 499, 62]\n"
     ]
    }
   ],
   "source": [
    "print([a.id for a in leaf])\n",
    "l = [a.id for a in leaf]\n",
    "print([a.id for a in inner])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48a2968-c67e-466f-93ee-78908e76455e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "6bdd7a6a-2c84-4db3-8aa8-0f1f530ef922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, "
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[214], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m leaf, inner \u001b[38;5;241m=\u001b[39m temp\u001b[38;5;241m.\u001b[39mprint_tree()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#print([a.id for a in leaf])\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#l = [a.id for a in leaf]\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#print([a.id for a in inner])\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mtemp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpruning\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m temp_preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(temp\u001b[38;5;241m.\u001b[39mpredict(X_test))\n\u001b[1;32m     12\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(Y_test, temp_preds)\n",
      "Cell \u001b[0;32mIn[210], line 127\u001b[0m, in \u001b[0;36mDecisionTree.pruning\u001b[0;34m(self, prunedList, tree)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpruning\u001b[39m(\u001b[38;5;28mself\u001b[39m, prunedList, tree\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m,end \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfound:\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tree\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'id'"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "max_accuracy = accuracy_score(Y_test, Y_pred)\n",
    "for node in inner:\n",
    "    print(node.id, end=\", \")\n",
    "    temp = copy.deepcopy(classifier)\n",
    "    leaf, inner = temp.print_tree()\n",
    "    #print([a.id for a in leaf])\n",
    "    #l = [a.id for a in leaf]\n",
    "    #print([a.id for a in inner])\n",
    "    temp.pruning([node.id])\n",
    "    temp_preds = list(temp.predict(X_test))\n",
    "    accuracy = accuracy_score(Y_test, temp_preds)\n",
    "    print(accuracy)\n",
    "    if accuracy > max_accuracy:\n",
    "        best_one = temp\n",
    "        max_accuracy = accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e79b12a-9b09-49e0-9c40-55351587dfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516ea8b4-cdad-4054-875d-236a27df9b11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
